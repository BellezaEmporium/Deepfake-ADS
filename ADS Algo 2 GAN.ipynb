{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb13a76",
   "metadata": {},
   "source": [
    "### Deepfakes - Travaux Jupyter Notebook pour ADS\n",
    "\n",
    "Ce projet à pour but de montrer deux moyens de créer des deepfakes. Leur usage est le même :\n",
    "\n",
    "- Les Autoencodeurs\n",
    "- Les Réseaux Génératifs Adversariaux (GAN)\n",
    "\n",
    "Tous deux ont pour but de produire la même chose : une imitation de quelque chose selon des images données.\n",
    "\n",
    "Dans les deux exemples, les modèles seront entraînés avec CelebA, une liste de têtes de célébrités connues, disponibles [ici](https://www.kaggle.com/jessicali9530/celeba-dataset)\n",
    "\n",
    "Pour les explications sur le fonctionnement des modèles, référez-vous au papier de l'ADS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b54cf0",
   "metadata": {},
   "source": [
    "### Partie 2 - GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ea8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "output = \"generated_images\" # Folder for generated images over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b918facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = \"img_align_celeba\" # input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cbba6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "btch_size = 32\n",
    "img_size = 64\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_directory, label_mode=None, image_size=(img_size, img_size), batch_size = btch_size\n",
    ")\n",
    "\n",
    "dataset = dataset.map(lambda x: x / 255.0).shuffle(btch_size).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68423071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 404,801\n",
      "Trainable params: 404,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The discriminator will be the one that'll judge if the image\n",
    "# done by the generator is real or fake.\n",
    "# It is made thanks to the LeakyReLU architecture.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(64, 64, 3)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904c6ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 8192)              4202496   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      524544    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 3)         38403     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,125,379\n",
      "Trainable params: 7,125,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The generator is a fully-convolutional network\n",
    "# that is going to generate the fake pictures\n",
    "# using the Conv2DTranspose (that will take the seed from the layers)\n",
    "# to generate the final picture.\n",
    "# Decodes with the help of given layers, and outputs an upsampled image\n",
    "latent_dim = 512\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(8 * 8 * 128),\n",
    "        layers.Reshape((8, 8, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4c5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Nous prenons des images aléatoires dans notre espace latent\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Nous les décodons en créant des fausses versions de ces images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Nous les combinons avec des vraies images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # On assemble les labels, puis nous le présentons au discriminateur\n",
    "        # qui devra déterminer le vrai du faux.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Ajout du bruit sur l'image (pour permettre de tromper le discriminateur !)\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # On entraîne le discriminateur\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Nous prenons des images aléatoires dans notre espace latent\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Nous prenons tous les labels qui pensent croire que les images sont 'réelles'\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # On entraîne le générateur (sans mettre à jour les poids du discriminateur, c'est très important)\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Mise à jour des métriques\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd76aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(f\"{output}/generated_img_%03d_%d.png\" % (epoch, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dfdec86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 55s 261ms/step - d_loss: 0.6766 - g_loss: 0.7962\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 57s 286ms/step - d_loss: 0.6788 - g_loss: 0.7874\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 61s 308ms/step - d_loss: 0.6789 - g_loss: 0.7899\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 65s 325ms/step - d_loss: 0.6773 - g_loss: 0.7957\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 67s 337ms/step - d_loss: 0.6768 - g_loss: 0.7918\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 69s 345ms/step - d_loss: 0.6795 - g_loss: 0.7916\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 71s 355ms/step - d_loss: 0.6791 - g_loss: 0.7964\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 72s 359ms/step - d_loss: 0.6783 - g_loss: 0.7915\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 73s 366ms/step - d_loss: 0.6782 - g_loss: 0.7967\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 74s 371ms/step - d_loss: 0.6784 - g_loss: 0.7937\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 74s 371ms/step - d_loss: 0.6784 - g_loss: 0.7949\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 75s 373ms/step - d_loss: 0.6807 - g_loss: 0.7951\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 75s 373ms/step - d_loss: 0.6773 - g_loss: 0.7885\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 75s 376ms/step - d_loss: 0.6799 - g_loss: 0.7959\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 75s 376ms/step - d_loss: 0.6794 - g_loss: 0.7918\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 76s 379ms/step - d_loss: 0.6789 - g_loss: 0.7899\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 76s 380ms/step - d_loss: 0.6775 - g_loss: 0.7911\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 1756s 9s/step - d_loss: 0.6787 - g_loss: 0.7907\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 54s 271ms/step - d_loss: 0.6785 - g_loss: 0.7958\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 62s 309ms/step - d_loss: 0.6800 - g_loss: 0.7946\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 68s 342ms/step - d_loss: 0.6796 - g_loss: 0.7865\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 68s 341ms/step - d_loss: 0.6808 - g_loss: 0.7936\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 71s 356ms/step - d_loss: 0.6786 - g_loss: 0.7927\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 75s 376ms/step - d_loss: 0.6796 - g_loss: 0.7843\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 77s 385ms/step - d_loss: 0.6786 - g_loss: 0.7872\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 78s 389ms/step - d_loss: 0.6775 - g_loss: 0.7937\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 81s 406ms/step - d_loss: 0.6781 - g_loss: 0.7874\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 83s 414ms/step - d_loss: 0.6799 - g_loss: 0.7918\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 87s 435ms/step - d_loss: 0.6797 - g_loss: 0.7852\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 91s 453ms/step - d_loss: 0.6794 - g_loss: 0.7911\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 94s 470ms/step - d_loss: 0.6777 - g_loss: 0.7935\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 97s 487ms/step - d_loss: 0.6779 - g_loss: 0.7919\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 93s 463ms/step - d_loss: 0.6799 - g_loss: 0.7906\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 98s 490ms/step - d_loss: 0.6806 - g_loss: 0.7862\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 100s 502ms/step - d_loss: 0.6805 - g_loss: 0.7853\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 102s 508ms/step - d_loss: 0.6797 - g_loss: 0.7916\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 99s 493ms/step - d_loss: 0.6783 - g_loss: 0.7877\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 99s 497ms/step - d_loss: 0.6804 - g_loss: 0.7899\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 102s 508ms/step - d_loss: 0.6796 - g_loss: 0.7914\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 104s 518ms/step - d_loss: 0.6790 - g_loss: 0.7900\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 104s 520ms/step - d_loss: 0.6791 - g_loss: 0.7869\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 107s 536ms/step - d_loss: 0.6801 - g_loss: 0.7906\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 116s 582ms/step - d_loss: 0.6807 - g_loss: 0.7901\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 111s 556ms/step - d_loss: 0.6798 - g_loss: 0.7873\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 103s 515ms/step - d_loss: 0.6809 - g_loss: 0.7905\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 101s 504ms/step - d_loss: 0.6799 - g_loss: 0.7868\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 112s 563ms/step - d_loss: 0.6799 - g_loss: 0.7926\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 113s 567ms/step - d_loss: 0.6814 - g_loss: 0.7825\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 116s 580ms/step - d_loss: 0.6794 - g_loss: 0.7879\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 118s 592ms/step - d_loss: 0.6806 - g_loss: 0.7926\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 116s 583ms/step - d_loss: 0.6785 - g_loss: 0.7891\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 113s 564ms/step - d_loss: 0.6806 - g_loss: 0.7883\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 115s 573ms/step - d_loss: 0.6803 - g_loss: 0.7888\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 115s 577ms/step - d_loss: 0.6804 - g_loss: 0.7918\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 120s 602ms/step - d_loss: 0.6814 - g_loss: 0.7866\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 124s 621ms/step - d_loss: 0.6815 - g_loss: 0.7854\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 119s 594ms/step - d_loss: 0.6798 - g_loss: 0.7922\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 118s 591ms/step - d_loss: 0.6818 - g_loss: 0.7876\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 111s 553ms/step - d_loss: 0.6791 - g_loss: 0.7859\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 110s 550ms/step - d_loss: 0.6801 - g_loss: 0.7824\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 113s 566ms/step - d_loss: 0.6806 - g_loss: 0.7910\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 115s 574ms/step - d_loss: 0.6816 - g_loss: 0.7902\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 108s 542ms/step - d_loss: 0.6806 - g_loss: 0.7839\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 106s 529ms/step - d_loss: 0.6798 - g_loss: 0.7921\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 112s 561ms/step - d_loss: 0.6811 - g_loss: 0.7868\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 108s 538ms/step - d_loss: 0.6826 - g_loss: 0.7900\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 107s 537ms/step - d_loss: 0.6808 - g_loss: 0.7842\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 108s 541ms/step - d_loss: 0.6813 - g_loss: 0.7821\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 108s 539ms/step - d_loss: 0.6820 - g_loss: 0.7888\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 108s 540ms/step - d_loss: 0.6805 - g_loss: 0.7921\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 106s 531ms/step - d_loss: 0.6811 - g_loss: 0.7862\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 108s 541ms/step - d_loss: 0.6807 - g_loss: 0.7858\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 103s 516ms/step - d_loss: 0.6817 - g_loss: 0.7875\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 102s 510ms/step - d_loss: 0.6803 - g_loss: 0.7884\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 103s 513ms/step - d_loss: 0.6803 - g_loss: 0.7875\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 101s 504ms/step - d_loss: 0.6818 - g_loss: 0.7861\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 100s 499ms/step - d_loss: 0.6813 - g_loss: 0.7833\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 106s 531ms/step - d_loss: 0.6806 - g_loss: 0.7846\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 106s 531ms/step - d_loss: 0.6800 - g_loss: 0.7859\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 104s 518ms/step - d_loss: 0.6802 - g_loss: 0.7871\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 100s 498ms/step - d_loss: 0.6823 - g_loss: 0.7855\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 99s 497ms/step - d_loss: 0.6806 - g_loss: 0.7881\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 102s 510ms/step - d_loss: 0.6812 - g_loss: 0.7851\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 102s 512ms/step - d_loss: 0.6793 - g_loss: 0.7919\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 102s 508ms/step - d_loss: 0.6816 - g_loss: 0.7876\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 99s 494ms/step - d_loss: 0.6819 - g_loss: 0.7836\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 99s 496ms/step - d_loss: 0.6813 - g_loss: 0.7823\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 95s 477ms/step - d_loss: 0.6824 - g_loss: 0.7841\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 97s 484ms/step - d_loss: 0.6810 - g_loss: 0.7855\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 108s 539ms/step - d_loss: 0.6805 - g_loss: 0.7878\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 104s 519ms/step - d_loss: 0.6808 - g_loss: 0.7884\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 110s 549ms/step - d_loss: 0.6824 - g_loss: 0.7928\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 104s 519ms/step - d_loss: 0.6800 - g_loss: 0.7832\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 114s 572ms/step - d_loss: 0.6801 - g_loss: 0.7858\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 105s 526ms/step - d_loss: 0.6823 - g_loss: 0.7854\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 106s 529ms/step - d_loss: 0.6798 - g_loss: 0.7911\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 108s 539ms/step - d_loss: 0.6808 - g_loss: 0.7841\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 107s 538ms/step - d_loss: 0.6814 - g_loss: 0.7860\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 108s 538ms/step - d_loss: 0.6814 - g_loss: 0.7819\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 108s 538ms/step - d_loss: 0.6812 - g_loss: 0.7894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x239c7cb0d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(0.00007, 0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(0.00007, 0.5),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)], steps_per_epoch = 200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce14b8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Saving the model\n",
    "generator.save('gen.h5')\n",
    "discriminator.save('disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576127d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
